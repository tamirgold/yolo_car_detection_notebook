{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tamirgold/yolo_car_detection_notebook/blob/main/Car_detection_using_YOLO5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtfuN2ZQPO6z",
        "outputId": "ce259992-7361-478a-c87a-192b1088d7c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 ðŸš€ 2022-12-4 Python-3.8.15 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
            "Adding AutoShape... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 69580  100 69580    0     0  45897      0  0:00:01  0:00:01 --:--:-- 45897\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1566k  100 1566k    0     0   574k      0  0:00:02  0:00:02 --:--:--  574k\n",
            "width, height: 320 240\n",
            "fps: 29.97002997002997\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import json\n",
        "\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
        "model.conf = 0.73\n",
        "\n",
        "\n",
        "!curl -o car_image.jpg https://images.all-free-download.com/images/graphiclarge/speeding_police_car_190499.jpg\n",
        "#Image result to json \n",
        "results = model(\"car_image.jpg\")\n",
        "\n",
        "cord_results = results.pandas().xyxy[0].to_dict(orient=\"records\")\n",
        "for i in range(len(cord_results)):\n",
        "  con = cord_results[i]['confidence']\n",
        "  cs = cord_results[i]['class']\n",
        "  x1 = int(cord_results[i]['xmin'])\n",
        "  y1 = int(cord_results[i]['ymin'])\n",
        "  x2 = int(cord_results[i]['xmax'])\n",
        "  y2 = int(cord_results[i]['ymax'])\n",
        "  dictionary = {\n",
        "      \"object_number\": i ,\n",
        "      \"x1\": x1,\n",
        "      \"x2\": x2,\n",
        "      \"y1\": y1,\n",
        "      \"y2\": y2\n",
        "  }\n",
        "  # Serializing json\n",
        "  json_object = json.dumps(dictionary, indent=4)\n",
        "  # Writing to sample.json\n",
        "  with open(\"bbox.json\", \"w\") as outfile:\n",
        "      outfile.write(json_object)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Download sample video\n",
        "!curl -o input_video.mp4 https://images.all-free-download.com/footage_preview/mp4/cars_moving_on_crowded_road_6891968.mp4\n",
        "cap = cv2.VideoCapture('input_video.mp4')\n",
        "img_arr = []\n",
        "\n",
        "if cap.isOpened(): \n",
        "    # get cap property \n",
        "    width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))   # int `width`\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))  # int `height`\n",
        "    print('width, height:', width, height)\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    print('fps:', fps)\n",
        "\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, image = cap.read()\n",
        "\n",
        "    if not ret:\n",
        "      break\n",
        "\n",
        "    #cv2_imshow(image) # Note cv2_imshow, not cv2.imshow\n",
        "    results = model(image)\n",
        "    img_arr.append(results.render()[0])\n",
        "\n",
        "cap.release()\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "\n",
        "out = cv2.VideoWriter('car_detection_output.mp4', fourcc, fps, (width, height))\n",
        "\n",
        "for i in range(len(img_arr)):\n",
        "    out.write(img_arr[i])\n",
        "out.release()\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1fT6TvqoJBa1aNLkhQ568BkOqRHZhAjoG",
      "authorship_tag": "ABX9TyNZ3gHGBhiSTag1HQY36sdk",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}